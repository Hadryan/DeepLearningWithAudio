# Tested data sets
- [ESC-50](https://github.com/karoldvl/ESC-50) (Use ```separate_files.py``` to sort into folders)
- [The Speech Commands dataset](https://storage.cloud.google.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz)
- [NSYNTH dataset](https://magenta.tensorflow.org/datasets/nsynth) (Use ```sort_nsynth.py``` to sort into folders)

The loader assumes that any data is put into a folder called input. You should create one and put any audio you have in organized folders within.


These are documentation files that are readable withing Github. Just click one and read.

* ```StateOfAudioML.md``` is about the current state and challenges of machine learning projects in the audio domain.
* ```UsingWavegan.md``` is a step-by-step guide on how to use [WaveGAN](https://github.com/chrisdonahue/wavegan).
* ```wavegantools``` is a folder for useful scripts to use with WaveGAN.
* ```images``` are just the images used in the documentation.
